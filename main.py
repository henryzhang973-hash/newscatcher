# coding=utf-8
"""
æ–°é—»çƒ­ç‚¹æ€»ç»“ç¨‹åº
åŠŸèƒ½ï¼šæŠ“å–å„å¹³å°å‰10æ¡çƒ­ç‚¹æ–°é—»ï¼Œä½¿ç”¨ AI ç”Ÿæˆè¦ç‚¹æ€»ç»“å¹¶æ¨é€åˆ°é£ä¹¦
"""

import json
import os
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

import pytz
import requests
import yaml

try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False


# === é…ç½®ç®¡ç† ===
def load_config() -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = os.environ.get("CONFIG_PATH", "config.yaml")
    
    if not Path(config_path).exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
    
    with open(config_path, "r", encoding="utf-8") as f:
        config_data = yaml.safe_load(f)
    
    # AI é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    ai_config = {
        "provider": os.environ.get("AI_PROVIDER", "openai").lower(),
        "api_key": os.environ.get("AI_API_KEY", ""),
        "base_url": os.environ.get("AI_BASE_URL", ""),
        "model": os.environ.get("AI_MODEL", config_data.get("ai", {}).get("model", "deepseek-chat")),
    }
    
    # é£ä¹¦é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    feishu_webhook = os.environ.get("FEISHU_WEBHOOK_URL", "").strip()
    
    config = {
        "platforms": config_data.get("platforms", []),
        "request_interval": config_data.get("request_interval", 1000),
        "top_n": int(os.environ.get("TOP_N", "10")),
        "ai": ai_config,
        "feishu_webhook": feishu_webhook,
    }
    
    return config


# === æ•°æ®è·å– ===
class DataFetcher:
    """æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        }
    
    def fetch_data(self, platform_id: str, max_retries: int = 2) -> Optional[Dict]:
        """è·å–å¹³å°æ•°æ®"""
        url = f"https://newsnow.busiyi.world/api/s?id={platform_id}&latest"
        
        for retry in range(max_retries + 1):
            try:
                response = requests.get(url, headers=self.headers, timeout=10)
                response.raise_for_status()
                data = response.json()
                
                if data.get("status") in ["success", "cache"]:
                    return data
            except Exception as e:
                if retry < max_retries:
                    time.sleep(2)
                else:
                    print(f"  âœ— æŠ“å–å¤±è´¥: {e}")
        return None
    
    def fetch_top_news(self, platforms: List[Dict], top_n: int = 10, request_interval: int = 1000) -> Dict[str, List[Dict]]:
        """æŠ“å–å„å¹³å°å‰Næ¡çƒ­ç‚¹æ–°é—»"""
        results = {}
        
        for i, platform in enumerate(platforms):
            platform_id = platform.get("id")
            platform_name = platform.get("name", platform_id)
            
            print(f"[{i+1}/{len(platforms)}] æ­£åœ¨æŠ“å– {platform_name}...")
            
            data = self.fetch_data(platform_id)
            
            if data:
                items = data.get("items", [])
                top_items = []
                
                for idx, item in enumerate(items[:top_n], 1):
                    title = item.get("title", "")
                    if title and str(title).strip():
                        top_items.append({
                            "rank": idx,
                            "title": str(title).strip(),
                        })
                
                results[platform_name] = top_items
                print(f"  âœ“ æˆåŠŸè·å– {len(top_items)} æ¡æ–°é—»")
            else:
                results[platform_name] = []
            
            if i < len(platforms) - 1:
                time.sleep(request_interval / 1000.0)
        
        return results


# === AI æ€»ç»“åŠŸèƒ½ ===
class AISummarizer:
    """AI æ€»ç»“å™¨"""
    
    def __init__(self, provider: str, api_key: str, model: str, base_url: Optional[str] = None):
        if not api_key:
            raise ValueError("AI API Key æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ AI_API_KEY")
        
        if provider != "openai" or not HAS_OPENAI:
            raise ImportError("è¯·å®‰è£… openai åº“: pip install openai")
        
        client_kwargs = {"api_key": api_key}
        if base_url:
            client_kwargs["base_url"] = base_url
        
        self.client = OpenAI(**client_kwargs)
        self.model = model
    
    def summarize_news(self, news_data: Dict[str, List[Dict]]) -> str:
        """ä½¿ç”¨ AI æ€»ç»“æ–°é—»"""
        prompt = self._build_prompt(news_data)
        
        print("\næ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆæ€»ç»“...")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»å¤šä¸ªå¹³å°çš„çƒ­ç‚¹æ–°é—»ä¸­æå–å…³é”®ä¿¡æ¯å¹¶ç”Ÿæˆç®€æ´æ˜äº†çš„æ€»ç»“ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
            )
            summary = response.choices[0].message.content
            print("âœ“ AI æ€»ç»“ç”ŸæˆæˆåŠŸ")
            return summary
        except Exception as e:
            raise Exception(f"AI æ€»ç»“å¤±è´¥: {e}")
    
    def _build_prompt(self, news_data: Dict[str, List[Dict]]) -> str:
        """æ„å»º AI æç¤ºè¯"""
        prompt_parts = [
            "è¯·åˆ†æä»¥ä¸‹å„å¹³å°çš„çƒ­ç‚¹æ–°é—»ï¼Œå¹¶ç”Ÿæˆä¸€ä»½è¦ç‚¹æ€»ç»“ã€‚",
            "\nè¦æ±‚ï¼š",
            "1. æŒ‰ä¸»é¢˜åˆ†ç±»æ•´ç†æ–°é—»ï¼ˆå¦‚ï¼šç§‘æŠ€ã€è´¢ç»ã€ç¤¾ä¼šã€å¨±ä¹ç­‰ï¼‰",
            "2. æå–æ¯ä¸ªä¸»é¢˜çš„æ ¸å¿ƒè¦ç‚¹ï¼ˆ3-5ä¸ªå…³é”®ä¿¡æ¯ï¼‰",
            "3. æ ‡æ³¨é‡è¦æ–°é—»çš„æ¥æºå¹³å°",
            "4. æ€»ç»“æ•´ä½“è¶‹åŠ¿å’Œçƒ­ç‚¹è¯é¢˜",
            "5. ä½¿ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€ï¼Œæ§åˆ¶åœ¨800-1200å­—",
            "\nå„å¹³å°çƒ­ç‚¹æ–°é—»ï¼š\n"
        ]
        
        for platform_name, news_list in news_data.items():
            if not news_list:
                continue
            prompt_parts.append(f"\nã€{platform_name}ã€‘")
            for news in news_list:
                prompt_parts.append(f"{news['rank']}. {news['title']}")
        
        prompt_parts.append("\nè¯·å¼€å§‹åˆ†æå¹¶ç”Ÿæˆæ€»ç»“ï¼š")
        return "\n".join(prompt_parts)


# === é£ä¹¦æ¨é€åŠŸèƒ½ ===
def format_feishu_content(summary: str) -> str:
    """æ ¼å¼åŒ–é£ä¹¦æ¶ˆæ¯å†…å®¹"""
    beijing_time = datetime.now(pytz.timezone("Asia/Shanghai"))
    time_str = beijing_time.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
    
    return f"""**ğŸ“Š çƒ­ç‚¹æ–°é—» AI æ€»ç»“æŠ¥å‘Š**

**ç”Ÿæˆæ—¶é—´ï¼š** {time_str}

---

{summary}

---

*æœ¬æŠ¥å‘Šç”± NewsCatcher è‡ªåŠ¨ç”Ÿæˆ*"""


def send_to_feishu(webhook_url: str, summary: str) -> bool:
    """å‘é€ AI æ€»ç»“åˆ°é£ä¹¦ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    feishu_content = format_feishu_content(summary)
    
    # é£ä¹¦æ¶ˆæ¯å¤§å°é™åˆ¶ï¼ˆçº¦ 30KBï¼‰
    feishu_batch_size = 29000
    content_bytes = feishu_content.encode("utf-8")
    
    if len(content_bytes) <= feishu_batch_size:
        batches = [feishu_content]
    else:
        # åˆ†æ‰¹å‘é€ï¼šæŒ‰æ®µè½åˆ†å‰²
        batches = []
        current_batch = ""
        paragraphs = feishu_content.split("\n\n")
        
        for para in paragraphs:
            test_batch = current_batch + ("\n\n" if current_batch else "") + para
            if len(test_batch.encode("utf-8")) <= feishu_batch_size:
                current_batch = test_batch
            else:
                if current_batch:
                    batches.append(current_batch)
                current_batch = para
        
        if current_batch:
            batches.append(current_batch)
    
    print(f"é£ä¹¦æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€")
    
    beijing_time = datetime.now(pytz.timezone("Asia/Shanghai"))
    time_str = beijing_time.strftime("%Y-%m-%d %H:%M:%S")
    
    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(f"å‘é€é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚")
        
        payload = {
            "msg_type": "text",
            "content": {
                "total_titles": 0,
                "timestamp": time_str,
                "report_type": "AI æ€»ç»“æŠ¥å‘Š",
                "text": batch_content,
            },
        }
        
        try:
            response = requests.post(webhook_url, headers=headers, json=payload, timeout=30)
            if response.status_code == 200:
                result = response.json()
                if result.get("StatusCode") == 0 or result.get("code") == 0:
                    print(f"âœ“ é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ")
                    if i < len(batches):
                        time.sleep(3)
                else:
                    error_msg = result.get("msg") or result.get("StatusMessage", "æœªçŸ¥é”™è¯¯")
                    print(f"âœ— é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ï¼Œé”™è¯¯ï¼š{error_msg}")
                    return False
            else:
                print(f"âœ— é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
                return False
        except Exception as e:
            print(f"âœ— é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ï¼š{e}")
            return False
    
    print(f"âœ“ é£ä¹¦æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ")
    return True


# === ä¸»ç¨‹åº ===
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("çƒ­ç‚¹æ–°é—»æ€»ç»“ç¨‹åº")
    print("=" * 80)
    
    try:
        # åŠ è½½é…ç½®
        print("\n[1/4] åŠ è½½é…ç½®...")
        config = load_config()
        print(f"  âœ“ é…ç½®åŠ è½½æˆåŠŸ")
        print(f"  - ç›‘æ§å¹³å°: {len(config['platforms'])} ä¸ª")
        print(f"  - æ¯ä¸ªå¹³å°æŠ“å–: å‰ {config['top_n']} æ¡")
        print(f"  - AI æ¨¡å‹: {config['ai']['model']}")
        
        # æ£€æŸ¥ AI é…ç½®
        if not config['ai']['api_key']:
            print("\nâŒ é”™è¯¯: æœªé…ç½® AI_API_KEY")
            return
        
        # æ£€æŸ¥é£ä¹¦é…ç½®
        if not config['feishu_webhook']:
            print("\nâŒ é”™è¯¯: æœªé…ç½® FEISHU_WEBHOOK_URL")
            return
        
        # æŠ“å–æ–°é—»
        print(f"\n[2/4] æŠ“å–å„å¹³å°çƒ­ç‚¹æ–°é—»...")
        fetcher = DataFetcher()
        news_data = fetcher.fetch_top_news(
            platforms=config['platforms'],
            top_n=config['top_n'],
            request_interval=config['request_interval'],
        )
        
        total_news = sum(len(news_list) for news_list in news_data.values())
        print(f"\n  âœ“ æŠ“å–å®Œæˆ: {len(news_data)} ä¸ªå¹³å°ï¼Œå…± {total_news} æ¡æ–°é—»")
        
        if total_news == 0:
            print("\nâš ï¸  æœªè·å–åˆ°ä»»ä½•æ–°é—»ï¼Œç¨‹åºé€€å‡º")
            return
        
        # AI æ€»ç»“
        print(f"\n[3/4] ä½¿ç”¨ AI ç”Ÿæˆæ€»ç»“...")
        summarizer = AISummarizer(
            provider=config['ai']['provider'],
            api_key=config['ai']['api_key'],
            model=config['ai']['model'],
            base_url=config['ai']['base_url'] if config['ai']['base_url'] else None,
        )
        
        summary = summarizer.summarize_news(news_data)
        
        # æ¨é€åˆ°é£ä¹¦
        print(f"\n[4/4] æ¨é€åˆ°é£ä¹¦...")
        success = send_to_feishu(config['feishu_webhook'], summary)
        
        if success:
            print("\n" + "=" * 80)
            print("âœ… ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
            print("=" * 80)
        else:
            print("\nâš ï¸  é£ä¹¦æ¨é€å¤±è´¥")
            raise Exception("é£ä¹¦æ¨é€å¤±è´¥")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        raise
    except Exception as e:
        print(f"\n\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()

